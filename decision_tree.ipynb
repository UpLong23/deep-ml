{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e89f4508",
   "metadata": {},
   "source": [
    "#### This is going to be an implementation of a Decision Tree \n",
    "as part of [deep-ML problem 20](https://www.deep-ml.com/problems/20).\n",
    "\n",
    "The implementation is using the ID3 algorithm. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "17178709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ebfc0f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(labels: list) -> float:\n",
    "    \"\"\"Calculate the entropy of a list of labels.\"\"\"\n",
    "    P = [i/len(labels) for i in list(Counter(labels).values())]\n",
    "    H =  sum(-p*math.log2(p) for p in P)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "10972fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_information_gain(examples: list[dict], attr: str, target_attr: str) -> float:\n",
    "    \n",
    "    \"\"\"\n",
    "    Information gain measures the reduction in entropy achieved by splitting \n",
    "    on a particular attribute.\n",
    "    Calculate the information gain of splitting on attr.\n",
    "    \"\"\"\n",
    "    D_size = len(examples)\n",
    "    labels = [example[target_attr] for example in examples]\n",
    "    H = calculate_entropy(labels) # entropy of the whole set\n",
    "\n",
    "    IG = H\n",
    "    \n",
    "    attr_tags_counts = Counter([example[attr] for example in examples])\n",
    "    for value in attr_tags_counts.keys():\n",
    "            subset = [example for example in examples if example[attr] == value]\n",
    "            subset_labels = [example[target_attr] for example in subset]\n",
    "            if subset_labels:\n",
    "                IG -= (len(subset) / D_size) * calculate_entropy(subset_labels)\n",
    "    return IG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "eabff94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_class(examples: list[dict], target_attr: str) -> str:\n",
    "    \"\"\"Return the majority class. Break ties alphabetically.\"\"\"\n",
    "    labels = [example[target_attr] for example in examples]\n",
    "    label_counts = Counter(labels)\n",
    "    max_count = max(label_counts.values())\n",
    "    \n",
    "    # Get all classes with max count (tie handling)\n",
    "    candidates = [label for label, count in label_counts.items() if count == max_count]\n",
    "    \n",
    "    # Return alphabetically first in case of tie\n",
    "    return sorted(candidates)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bf8e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Outlook': {'Sunny': 'No',\n",
       "  'Overcast': 'Yes',\n",
       "  'Rain': {'Wind': {'Weak': 'Yes', 'Strong': 'No'}}}}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def learn_decision_tree(examples: list[dict], attributes: list[str], target_attr: str) -> dict:\n",
    "    \"\"\"Build a decision tree using the ID3 algorithm.\"\"\"\n",
    "    # get the unique labels from the examples \n",
    "    unique_labels = list(Counter([example[target_attr] for example in examples]))\n",
    "    if len(unique_labels) == 1: # leaf perfect split\n",
    "        return  unique_labels[0]\n",
    "    \n",
    "    if len(attributes) == 0: # leaf no more possible split\n",
    "        return majority_class(examples, target_attr)\n",
    "    \n",
    "    # use IG\n",
    "    best_attr = max(attributes, key= lambda x: calculate_information_gain(examples, x, target_attr))\n",
    "\n",
    "    tree = {best_attr:{}}\n",
    "\n",
    "    remaining_attributes = [attr for attr in attributes if attr!=best_attr]\n",
    "\n",
    "    best_attr_vals = Counter([example[best_attr] for example in examples]).keys()\n",
    "    for val in best_attr_vals:\n",
    "        subset = [example for example in examples if example[best_attr] == val]\n",
    "        tree[best_attr][val] = learn_decision_tree(subset, remaining_attributes, target_attr)\n",
    "\n",
    "    return tree\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "eb49327b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "best_attr_vals = Counter([example['Outlook'] for example in examples]).keys()\n",
    "\n",
    "for val in best_attr_vals:\n",
    "    print(len([example for example in examples if example['Outlook'] == val]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
